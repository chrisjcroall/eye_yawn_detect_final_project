{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "# Initialize pygame mixer\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Load face detector and facial landmark predictor\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat') # Path to facial landmark predictor file (.dat format)\n",
    "\n",
    "# Function to calculate eye aspect ratio\n",
    "def eye_aspect_ratio(eye_points):\n",
    "    # Vertical distances\n",
    "    vertical_1 = ((eye_points[1].x - eye_points[5].x) ** 2 + (eye_points[1].y - eye_points[5].y) ** 2) ** 0.5\n",
    "    vertical_2 = ((eye_points[2].x - eye_points[4].x) ** 2 + (eye_points[2].y - eye_points[4].y) ** 2) ** 0.5\n",
    "\n",
    "    # Horizontal distance\n",
    "    horizontal = ((eye_points[0].x - eye_points[3].x) ** 2 + (eye_points[0].y - eye_points[3].y) ** 2) ** 0.5\n",
    "\n",
    "    # Eye aspect ratio\n",
    "    ear = (vertical_1 + vertical_2) / (2.0 * horizontal)\n",
    "    return ear\n",
    "\n",
    "# Function to detect closed eyes\n",
    "def detect_closed_eyes(frame, landmarks):\n",
    "    left_eye_points = [landmarks.part(i) for i in range(36, 42)]\n",
    "    right_eye_points = [landmarks.part(i) for i in range(42, 48)]\n",
    "\n",
    "    left_ear = eye_aspect_ratio(left_eye_points)\n",
    "    right_ear = eye_aspect_ratio(right_eye_points)\n",
    "\n",
    "    # Average eye aspect ratio\n",
    "    ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "    # Draw eyes\n",
    "    for i in range(36, 48):\n",
    "        cv2.circle(frame, (landmarks.part(i).x, landmarks.part(i).y), 1, (255, 255, 255), -2)\n",
    "\n",
    "    return ear\n",
    "\n",
    "# Function to detect yawning\n",
    "def detect_yawn(frame, landmarks, mouth_open_threshold):\n",
    "    # Get the mouth region from landmarks\n",
    "    mouth_points = [landmarks.part(i) for i in range(48, 68)]\n",
    "\n",
    "    if len(mouth_points) == 20:\n",
    "        # Calculate the aspect ratio of the mouth\n",
    "        mouth_width = abs(mouth_points[6].x - mouth_points[0].x)\n",
    "        mouth_height = abs(mouth_points[3].y - mouth_points[9].y)\n",
    "        aspect_ratio = mouth_height / mouth_width\n",
    "\n",
    "        # Draw lines or dots around the mouth\n",
    "        for i in range(20):\n",
    "            cv2.circle(frame, (mouth_points[i].x, mouth_points[i].y), 1, (255, 255, 255), -1)\n",
    "            cv2.line(frame, (mouth_points[i].x, mouth_points[i].y), (mouth_points[(i + 1) % 20].x, mouth_points[(i + 1) % 20].y),\n",
    "                     (255, 255, 255), ) # Draw a line between the mouth points\n",
    "        cv2.line(frame, (mouth_points[0].x, mouth_points[0].y), (mouth_points[19].x, mouth_points[19].y), (255, 255, 255, 0), 1)\n",
    "\n",
    "        return aspect_ratio > mouth_open_threshold\n",
    "\n",
    "    return False\n",
    "\n",
    "# Open video capture (replace 'path_to_video' with 0 for webcam detection)\n",
    "cap = cv2.VideoCapture(\"Driver_Drowsiness.mp4\")\n",
    "\n",
    "# Set the window name\n",
    "window_name = \"Fatigue Detection\"\n",
    "\n",
    "# Create a resizable window\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "\n",
    "# Set the initial window size\n",
    "cv2.resizeWindow(window_name, 640, 480)\n",
    "\n",
    "# Initialize variables for eye detection and score\n",
    "closed_eye_start = None\n",
    "closed_eye_alert_threshold = 0.5  # Number of seconds with closed eyes required to show the alert\n",
    "\n",
    "eye_closed_count = 0  # Counter variable for eye closed detections\n",
    "yawn_count = 0  # Counter variable for yawn detections\n",
    "yawning = False  # Flag to indicate if a yawn is in progress\n",
    "\n",
    "# Load the sound files\n",
    "sound_file_alert = \"elevator-tone-2863.wav\" \n",
    "sound_alert = pygame.mixer.Sound(sound_file_alert)\n",
    "\n",
    "# Flag to check if the alert has been given\n",
    "alert_given = False\n",
    "\n",
    "# Flag to check if the audio alert is playing\n",
    "audio_alert_playing = False\n",
    "audio_alert_start_time = None\n",
    "audio_alert_duration = 1  # Number of seconds to play the audio alert\n",
    "\n",
    "# Initialize variables for counting seconds and detections\n",
    "start_time = time.time()\n",
    "\n",
    "# Process video frames until the user exits\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the frame in the resized window\n",
    "    cv2.imshow(window_name, frame)\n",
    "\n",
    "    # Detect faces using dlib's face detector\n",
    "    faces = face_detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        # Detect landmarks in the face region\n",
    "        landmarks = landmark_predictor(gray, face)\n",
    "\n",
    "        # Detect closed eyes\n",
    "        ear = detect_closed_eyes(frame, landmarks)\n",
    "\n",
    "        # Check if eyes are closed\n",
    "        ear_threshold = 0.25  # Adjust this value as desired\n",
    "        if ear < ear_threshold:\n",
    "            if closed_eye_start is None:\n",
    "                closed_eye_start = time.time()\n",
    "            else:\n",
    "                closed_eye_duration = time.time() - closed_eye_start\n",
    "\n",
    "                # Check if the closed eye duration exceeds the alert threshold\n",
    "                if closed_eye_duration >= closed_eye_alert_threshold and not alert_given:\n",
    "                    cv2.putText(frame, \"Drowsiness Detected\", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    sound_alert.play()  # Play the alert sound\n",
    "                    alert_given = True\n",
    "                    eye_closed_count += 1  # Increment eye closed count\n",
    "\n",
    "                # Check if the closed eye duration exceeds the audio alert duration\n",
    "                if closed_eye_duration >= audio_alert_duration and not audio_alert_playing:\n",
    "                    sound_alert.play()  # Play the alert sound\n",
    "                    audio_alert_playing = True\n",
    "                    audio_alert_start_time = time.time()\n",
    "\n",
    "                # Check if the audio alert duration has exceeded and repeat the audio alert\n",
    "                if audio_alert_playing and time.time() - audio_alert_start_time >= audio_alert_duration:\n",
    "                    sound_alert.play()  # Play the alert sound\n",
    "                    audio_alert_start_time = time.time()\n",
    "\n",
    "        else:\n",
    "            closed_eye_start = None # Reset closed eye start timer\n",
    "            alert_given = False\n",
    "            audio_alert_playing = False\n",
    "\n",
    "        # Detect yawning\n",
    "        yawn_threshold = 1.5  # Adjust this value as desired\n",
    "        if detect_yawn(frame, landmarks, yawn_threshold):\n",
    "            if not yawning:\n",
    "                cv2.putText(frame, \"Yawn Detected\", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                yawn_count += 1  # Increment detection count\n",
    "                yawning = True\n",
    "        else:\n",
    "            yawning = False\n",
    "\n",
    "        # Draw a rectangle around the face\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the detection counts on the frame\n",
    "    text1 = f\"Eye Closed Count: {eye_closed_count}\"\n",
    "    text2 = f\"Yawn Count: {yawn_count}\"\n",
    "\n",
    "    # Determine the text size\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    thickness = 1\n",
    "    text1_size, _ = cv2.getTextSize(text1, font, font_scale, thickness)\n",
    "    text2_size, _ = cv2.getTextSize(text2, font, font_scale, thickness)\n",
    "\n",
    "    # Calculate the box dimensions based on text size\n",
    "    box1_width = text1_size[0] + 10\n",
    "    box1_height = text1_size[1] + 10\n",
    "    box1_coords = (20, frame.shape[0] - box1_height - 40)  # Adjust the y-coordinate to position it at the bottom\n",
    "\n",
    "    box2_width = text2_size[0] + 10\n",
    "    box2_height = text2_size[1] + 10\n",
    "    box2_coords = (20, frame.shape[0] - box2_height - 10)  # Adjust the y-coordinate to position it at the bottom\n",
    "\n",
    "    # Draw white boxes around the text\n",
    "    cv2.rectangle(frame, box1_coords, (box1_coords[0] + box1_width, box1_coords[1] + box1_height), (255, 255, 255), cv2.FILLED)\n",
    "    cv2.rectangle(frame, box2_coords, (box2_coords[0] + box2_width, box2_coords[1] + box2_height), (255, 255, 255), cv2.FILLED)\n",
    "\n",
    "    # Draw the text on the white boxes\n",
    "    cv2.putText(frame, text1, (box1_coords[0] + 5, box1_coords[1] + text1_size[1] + 5), font, font_scale, (0, 0, 0), thickness)\n",
    "    cv2.putText(frame, text2, (box2_coords[0] + 5, box2_coords[1] + text2_size[1] + 5), font, font_scale, (0, 0, 0), thickness)\n",
    "\n",
    "    # Calculate and display elapsed time\n",
    "    elapsed_time = time.time() - start_time\n",
    "    cv2.putText(frame, f\"Elapsed Time: {elapsed_time:.2f} seconds\", (350, 450), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Fatigue Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
